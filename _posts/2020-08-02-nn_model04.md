---
layout: post
title: Python神经网络模型（四），GANs
categories: [Python, NNs]
mathjax: true
---

对抗生成网络

<!-- more -->
## GAN(Generative Adversarial Networks)
### 判别器  
1. 目标$maxV(G,D)=E_{x\sim p_r(x)}[log(D(x))] + E_{z\sim p_z(z)}[log(1-D(G(z)))]$

2. $D(x)$越大越好  
反映在loss中，真样本经d判别，结果与1越接近，d就越优秀，损失越小；

3. $1-D(G(z))$越大越好，则$D(G(z))$越小越好  
反映在loss中，假样本经d判别，判断结果与0越接近，d就越优秀，损失越小

### 生成器  
1. 目标$minV(G,D)=E_{x\sim p_g(x)}[log(1-D(x))]$

3. $1-D(x)$越小越好，$D(x)$越大越好  
反映在loss中，假样本经d判别，判断结果与1越接近，g就越优秀，损失越小

### 纳什均衡
1. D：固定$G(x)$  
$V(G,D)=\int p_r(x)\log(D(x)))dx + \int p_g(x)\log(1-D(x)))dx$  
令$p_r(x)=A,p_g(x)=B$  
则$V^\prime=\frac{1}{ln10}\frac{A-(A+B)x}{x(1-x)}$  
令$V^\prime=0$，得极值点（最优判别器）$D^\ast=\frac{A}{A+B}=\frac{p_r(x)}{p_r(x)+p_g(x)}$

2. G：固定$D(x)$为$D^\ast$，使用JS散度来衡量两分布的距离  
$$\begin{align}D_{JS}(p_r \Vert p_g) 
&=\frac{1}{2}D_{KL}(p_r \Vert \frac{p_r+p_g}{2})+\frac{1}{2}D_KL(p_g \Vert \frac{p_r+p_g}{2})\\\
&=\frac{1}{2}(log2+\int p_r(x)\log \frac{p_r(x)}{p_r(x)+p_g(x)}dx)\\\
&+\frac{1}{2}(log2+\int p_g(x)\log \frac{p_g(x)}{p_r(x)+p_g(x)}dx)\\\
&=\frac{1}{2}(log4+V(G,D^\ast))\end{align}$$

### 缺陷推导
1. 生成器目标改进  
$E_{x\sim p_g(x)}[log(1-D(x))] \to E_{x\sim p_g(x)}[-logD(x)],(1)$  

2. 在最优判别器$D^\ast$下  
$E_{x\sim p_r(x)}[log(D^\ast (x))] + E_{z\sim p_z(z)}[log(1-D^\ast (G(z)))]=2D_{JS}(p_r \Vert p_g)+2log2,(2)$  

3. 把KL散度（先g后r）变换成含$ D^\ast$的形式  
$$\begin{align}D_{KL}(p_g \Vert p_r)
&=E_{x\sim p_g(x)}[log\frac{p_g(x)}{p_r(x)}]\\\
&=E_{x\sim p_g(x)}[log\frac{\frac{p_g(x)}{p_r(x)+p_g(x)}}{\frac{p_r(x)}{p_r(x)+p_g(x)}}]\\\
&=E_{x\sim p_g(x)}[log\frac{1-D^\ast(x)}{D^\ast(x)}]\\\
&=E_{x\sim p_g(x)}log[1-D^\ast(x)] - E_{x\sim p_g(x)}logD^\ast(x),(3)\end{align}$$

4. 由(1)(2)(3)得  
$E_{x\sim p_g(x)}[-logD(x)]=D_{KL}(p_g \Vert p_r)+E_{x\sim p_r(x)}[log(D^\ast (x))]-2D_{JS}(p_r \Vert p_g)-2log2$

5. 总结
   1. 第一项最小化生成分布与真实分布的KL散度，而KL散度不对称，对多样性惩罚小，对准确性惩罚大，导致模式崩溃
   生成器倾向于生成准确但是单一的样本
   
   2. 第二项却又要最大化两者的JS散度，非常荒谬，在数值上则会导致梯度不稳定；  
   甚至生成分布与真实分布无重叠部分，loss保持不变，导致梯度消失

## WGAN(Wasserstein GAN)
权重剪裁，限制了网络的表达能力

## WGAN-GP(WGAN Gradient Penalty)
